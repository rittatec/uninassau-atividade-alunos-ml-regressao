# ü§ñ Etapa 3: Modelos de Machine Learning

**Prazo de Entrega:** [Data ser√° informada pelo professor]
**Peso:** 25% da nota do projeto (2.5 pontos)
**Entreg√°veis:**
- `notebooks/03_Modelagem.ipynb`
- Apresenta√ß√£o de 15 minutos

---

## üéØ Objetivos da Etapa

Ao final desta etapa, voc√™ deve:

1. **Treinar m√∫ltiplos modelos** - Testar pelo menos 5 algoritmos diferentes
2. **Avaliar desempenho** - Comparar modelos usando m√©tricas apropriadas
3. **Validar corretamente** - Usar valida√ß√£o cruzada e conjunto de valida√ß√£o
4. **Selecionar melhor modelo** - Escolher modelo com melhor desempenho

---

## üìã O Que Voc√™ Vai Entregar

### 1. Notebook Principal
**`notebooks/03_Modelagem.ipynb`**

Se√ß√µes obrigat√≥rias:
1. Importa√ß√£o e Carregamento dos Dados Processados
2. Defini√ß√£o de M√©tricas de Avalia√ß√£o
3. Modelo Baseline (Regress√£o Linear)
4. Modelos Avan√ßados (pelo menos 5 algoritmos)
5. Valida√ß√£o Cruzada
6. Compara√ß√£o de Modelos
7. An√°lise de Erros
8. Conclus√µes e Sele√ß√£o do Melhor Modelo

### 2. Apresenta√ß√£o (15 minutos) üé§

**O que apresentar:**
- Modelos testados e por qu√™ escolheu cada um
- M√©tricas utilizadas e justificativa
- Compara√ß√£o de desempenho (gr√°ficos!)
- Melhor modelo e suas caracter√≠sticas
- An√°lise de erros do melhor modelo
- Pr√≥ximos passos (Etapa 4)

**Formato:**
- 8-10 slides
- Todos os membros do grupo devem participar
- Inclua gr√°ficos comparativos (barras, boxplots)
- Demonstre 1-2 exemplos de predi√ß√£o

**Crit√©rios de avalia√ß√£o da apresenta√ß√£o:**
- Clareza t√©cnica (30%)
- An√°lise comparativa (30%)
- Visualiza√ß√µes de resultados (20%)
- Participa√ß√£o de todos (20%)

---

## üîç Modelos Obrigat√≥rios

### Modelo Baseline
**Regress√£o Linear Simples**
```python
from sklearn.linear_model import LinearRegression

baseline = LinearRegression()
baseline.fit(X_train, y_train)
```

### Modelos Avan√ßados (escolha pelo menos 5)

**Obrigat√≥rio testar:**
1. **Ridge Regression** ou **Lasso Regression**
2. **Decision Tree Regressor**
3. **Random Forest Regressor**
4. **Gradient Boosting** (XGBoost, LightGBM, ou CatBoost)
5. **Support Vector Regressor** ou **KNN Regressor** ou **Elastic Net**

**Exemplo de c√≥digo:**
```python
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.tree import DecisionTreeRegressor

models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(random_state=42),
    'XGBoost': XGBRegressor(random_state=42),
    'Decision Tree': DecisionTreeRegressor(random_state=42),
    # ... adicione mais 2
}
```

---

## üìä M√©tricas Obrigat√≥rias

Para **regress√£o**, calcule:

1. **MAE** (Mean Absolute Error)
2. **MSE** (Mean Squared Error)
3. **RMSE** (Root Mean Squared Error)
4. **R¬≤** (R-squared)
5. **MAPE** (Mean Absolute Percentage Error) - opcional

**C√≥digo esperado:**
```python
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

mae = mean_absolute_error(y_true, y_pred)
mse = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_true, y_pred)

print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"R¬≤: {r2:.4f}")
```

---

## üî¨ An√°lises Obrigat√≥rias

### 1. Treinamento de Todos os Modelos

Loop pelos modelos:
```python
results = {}

for name, model in models.items():
    # Treinar
    model.fit(X_train, y_train)

    # Predizer no conjunto de valida√ß√£o
    y_pred = model.predict(X_val)

    # Calcular m√©tricas
    mae = mean_absolute_error(y_val, y_pred)
    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
    r2 = r2_score(y_val, y_pred)

    results[name] = {'MAE': mae, 'RMSE': rmse, 'R¬≤': r2}
```

### 2. Valida√ß√£o Cruzada

**Obrigat√≥rio:**
```python
from sklearn.model_selection import cross_val_score

for name, model in models.items():
    scores = cross_val_score(
        model, X_train, y_train,
        cv=5,  # 5-fold cross-validation
        scoring='neg_mean_absolute_error'
    )
    print(f"{name} - CV MAE: {-scores.mean():.2f} (+/- {scores.std():.2f})")
```

### 3. Compara√ß√£o Visual

**Crie gr√°ficos:**

#### Gr√°fico de Barras - Compara√ß√£o de MAE
```python
import matplotlib.pyplot as plt

models_names = list(results.keys())
mae_values = [results[m]['MAE'] for m in models_names]

plt.figure(figsize=(10, 6))
plt.barh(models_names, mae_values)
plt.xlabel('MAE (menor √© melhor)')
plt.title('Compara√ß√£o de Modelos - MAE')
plt.show()
```

#### Scatter Plot - Predito vs Real
```python
# Para o melhor modelo
plt.figure(figsize=(8, 8))
plt.scatter(y_val, y_pred, alpha=0.5)
plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)
plt.xlabel('Valores Reais')
plt.ylabel('Valores Preditos')
plt.title('Predito vs Real - [Nome do Modelo]')
plt.show()
```

### 4. An√°lise de Erros

**Obrigat√≥rio:**
```python
# Res√≠duos
residuals = y_val - y_pred

# Histograma dos res√≠duos
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.hist(residuals, bins=30, edgecolor='black')
plt.xlabel('Res√≠duo (Real - Predito)')
plt.title('Distribui√ß√£o dos Res√≠duos')

# Q-Q Plot
plt.subplot(1, 2, 2)
from scipy import stats
stats.probplot(residuals, plot=plt)
plt.title('Q-Q Plot dos Res√≠duos')
plt.tight_layout()
plt.show()
```

### 5. Feature Importance (para modelos tree-based)

**Se usar Random Forest ou XGBoost:**
```python
# Feature importance
importances = model.feature_importances_
feature_names = X_train.columns

# Ordenar
indices = np.argsort(importances)[::-1][:10]  # Top 10

plt.figure(figsize=(10, 6))
plt.barh(range(10), importances[indices])
plt.yticks(range(10), [feature_names[i] for i in indices])
plt.xlabel('Import√¢ncia')
plt.title('Top 10 Features Mais Importantes')
plt.show()
```

---

## ‚úÖ Crit√©rios de Avalia√ß√£o

| Crit√©rio | Peso | O Que Avaliamos |
|----------|:----:|-----------------|
| **Variedade de Modelos** | 20% | Pelo menos 5 modelos diferentes testados |
| **M√©tricas e Avalia√ß√£o** | 25% | M√©tricas corretas, valida√ß√£o cruzada |
| **An√°lise Comparativa** | 25% | Compara√ß√£o clara, visualiza√ß√µes, interpreta√ß√µes |
| **Documenta√ß√£o** | 15% | Markdown explicativo, decis√µes justificadas |
| **Apresenta√ß√£o** | 15% | Clareza, participa√ß√£o, visualiza√ß√µes |

---

## üì¶ Como Entregar

### 1. Commit e Push
```bash
git add notebooks/03_Modelagem.ipynb
git commit -m "feat: Completa Etapa 3 - Modelagem"
git push origin main
```

### 2. Apresenta√ß√£o
- Upload dos slides em `docs/apresentacao_etapa3.pdf`
- Apresentar na aula marcada pelo professor

---

## üí° Dicas Importantes

**DO:**
‚úÖ Teste TODOS os modelos com os mesmos dados
‚úÖ Use valida√ß√£o cruzada para confirmar resultados
‚úÖ Interprete as m√©tricas (n√£o apenas calcule!)
‚úÖ Analise ONDE o modelo erra (n√£o s√≥ QUANTO erra)
‚úÖ Documente hiperpar√¢metros usados

**DON'T:**
‚ùå Treinar no conjunto de teste (data leakage!)
‚ùå Comparar modelos com m√©tricas diferentes
‚ùå Escolher modelo s√≥ pelo R¬≤ (veja outras m√©tricas!)
‚ùå Esquecer de normalizar dados (se necess√°rio)

---

## üéØ Checklist Antes de Entregar

- [ ] Pelo menos 5 modelos diferentes treinados
- [ ] Valida√ß√£o cruzada executada
- [ ] M√©tricas calculadas (MAE, RMSE, R¬≤)
- [ ] Gr√°ficos comparativos criados
- [ ] An√°lise de res√≠duos feita
- [ ] Melhor modelo identificado e justificado
- [ ] Notebook executa "Restart & Run All" sem erros
- [ ] Apresenta√ß√£o preparada (8-10 slides)
- [ ] Todos os membros do grupo participam da apresenta√ß√£o

---

## üÜò Precisa de Ajuda?

**D√∫vidas comuns:**
- Qual modelo usar? ‚Üí Teste v√°rios! N√£o d√° para saber a priori
- R¬≤ negativo? ‚Üí Modelo muito ruim ou erro na implementa√ß√£o
- Overfitting? ‚Üí Etapa 4 vai tratar isso (regulariza√ß√£o e tuning)

**Consulte:**
- Scikit-learn model selection: https://scikit-learn.org/stable/model_selection.html
- XGBoost docs: https://xgboost.readthedocs.io/
- Material da aula de modelagem

---

**Boa modelagem!** ü§ñ

*√öltima atualiza√ß√£o: Outubro 2027*
