# ‚ö° Etapa 4: Otimiza√ß√£o e Tuning de Hiperpar√¢metros

**Prazo de Entrega:** [Data ser√° informada pelo professor]
**Peso:** 25% da nota do projeto (2.5 pontos)
**Entreg√°veis:**
- `notebooks/04_Otimizacao.ipynb`
- Modelo final salvo
- Apresenta√ß√£o de 15 minutos

---

## üéØ Objetivos da Etapa

Ao final desta etapa, voc√™ deve:

1. **Otimizar hiperpar√¢metros** - Tuning do melhor modelo da Etapa 3
2. **Evitar overfitting** - T√©cnicas de regulariza√ß√£o e valida√ß√£o
3. **Avaliar no conjunto de teste** - Desempenho final do modelo
4. **Salvar modelo final** - Modelo treinado pronto para produ√ß√£o

---

## üìã O Que Voc√™ Vai Entregar

### 1. Notebook Principal
**`notebooks/04_Otimizacao.ipynb`**

Se√ß√µes obrigat√≥rias:
1. Recapitula√ß√£o dos Resultados da Etapa 3
2. Sele√ß√£o do Modelo para Otimiza√ß√£o
3. Grid Search ou Random Search
4. An√°lise dos Melhores Hiperpar√¢metros
5. Treinamento do Modelo Final
6. Avalia√ß√£o no Conjunto de Teste
7. An√°lise de Erros Detalhada
8. Salvamento do Modelo
9. Conclus√µes Finais

### 2. Modelo Treinado
**`models/modelo_final.pkl`** (ou `.joblib`)
- Modelo otimizado e treinado
- Pronto para fazer predi√ß√µes

### 3. Apresenta√ß√£o (15 minutos) üé§

**O que apresentar:**
- Recapitula√ß√£o: melhor modelo da Etapa 3
- Processo de otimiza√ß√£o de hiperpar√¢metros
- Hiperpar√¢metros testados vs selecionados
- Compara√ß√£o: modelo antes vs depois da otimiza√ß√£o
- Desempenho final no conjunto de teste
- An√°lise de erros e limita√ß√µes
- Poss√≠veis melhorias futuras

**Formato:**
- 8-12 slides
- Todos os membros do grupo devem participar
- Inclua gr√°ficos de compara√ß√£o
- Mostre exemplos de predi√ß√µes

**Crit√©rios de avalia√ß√£o da apresenta√ß√£o:**
- Profundidade t√©cnica (35%)
- An√°lise cr√≠tica do modelo (25%)
- Visualiza√ß√µes e clareza (20%)
- Participa√ß√£o de todos (20%)

---

## üîç An√°lises Obrigat√≥rias

### 1. Otimiza√ß√£o de Hiperpar√¢metros

**Escolha uma t√©cnica:**

#### Op√ß√£o A: Grid Search (Busca Exaustiva)
```python
from sklearn.model_selection import GridSearchCV

# Definir grid de hiperpar√¢metros
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Grid Search
grid_search = GridSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_grid=param_grid,
    cv=5,  # 5-fold cross-validation
    scoring='neg_mean_absolute_error',
    n_jobs=-1,  # usar todos os processadores
    verbose=2
)

grid_search.fit(X_train, y_train)

print("Melhores hiperpar√¢metros:", grid_search.best_params_)
print("Melhor score:", -grid_search.best_score_)
```

#### Op√ß√£o B: Random Search (Mais R√°pido)
```python
from sklearn.model_selection import RandomizedSearchCV
import numpy as np

# Distribui√ß√µes de hiperpar√¢metros
param_distributions = {
    'n_estimators': [100, 200, 300, 400, 500],
    'max_depth': [10, 20, 30, 40, 50, None],
    'min_samples_split': [2, 5, 10, 15],
    'min_samples_leaf': [1, 2, 4, 6],
    'max_features': ['auto', 'sqrt', 'log2']
}

random_search = RandomizedSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_distributions=param_distributions,
    n_iter=50,  # 50 combina√ß√µes aleat√≥rias
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1,
    verbose=2,
    random_state=42
)

random_search.fit(X_train, y_train)

print("Melhores hiperpar√¢metros:", random_search.best_params_)
```

### 2. An√°lise dos Resultados do Tuning

**Visualizar o processo:**
```python
# Converter resultados em DataFrame
results_df = pd.DataFrame(grid_search.cv_results_)

# Top 10 melhores combina√ß√µes
top_10 = results_df.nsmallest(10, 'rank_test_score')[
    ['params', 'mean_test_score', 'std_test_score']
]
print(top_10)

# Gr√°fico de compara√ß√£o
plt.figure(figsize=(12, 6))
plt.errorbar(
    range(len(top_10)),
    -top_10['mean_test_score'],
    yerr=top_10['std_test_score'],
    fmt='o-'
)
plt.xlabel('Configura√ß√£o')
plt.ylabel('MAE')
plt.title('Top 10 Configura√ß√µes de Hiperpar√¢metros')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

### 3. Treinamento do Modelo Final

**Treinar com melhores hiperpar√¢metros:**
```python
# Obter melhor modelo
best_model = grid_search.best_estimator_

# OU treinar manualmente com os melhores par√¢metros
final_model = RandomForestRegressor(
    n_estimators=200,
    max_depth=20,
    min_samples_split=5,
    # ... outros par√¢metros
    random_state=42
)

# Treinar no conjunto de TREINO + VALIDA√á√ÉO
X_train_full = pd.concat([X_train, X_val])
y_train_full = pd.concat([y_train, y_val])

final_model.fit(X_train_full, y_train_full)
```

### 4. Avalia√ß√£o Final no Conjunto de Teste

**‚ö†Ô∏è IMPORTANTE:** S√≥ use o conjunto de teste UMA VEZ!

```python
# Predi√ß√µes no conjunto de teste
y_test_pred = final_model.predict(X_test)

# Calcular m√©tricas finais
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

mae_test = mean_absolute_error(y_test, y_test_pred)
rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))
r2_test = r2_score(y_test, y_test_pred)

print("="*50)
print("DESEMPENHO FINAL NO CONJUNTO DE TESTE")
print("="*50)
print(f"MAE:  {mae_test:.2f}")
print(f"RMSE: {rmse_test:.2f}")
print(f"R¬≤:   {r2_test:.4f}")
print("="*50)
```

### 5. Compara√ß√£o: Antes vs Depois da Otimiza√ß√£o

**Crie tabela comparativa:**
```python
comparison = pd.DataFrame({
    'M√©trica': ['MAE', 'RMSE', 'R¬≤'],
    'Antes (Etapa 3)': [mae_antes, rmse_antes, r2_antes],
    'Depois (Etapa 4)': [mae_test, rmse_test, r2_test],
    'Melhoria (%)': [
        ((mae_antes - mae_test) / mae_antes) * 100,
        ((rmse_antes - rmse_test) / rmse_antes) * 100,
        ((r2_test - r2_antes) / r2_antes) * 100
    ]
})

print(comparison)
```

### 6. An√°lise de Erros Detalhada

**Gr√°ficos obrigat√≥rios:**

#### Scatter: Predito vs Real
```python
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
         'r--', lw=2, label='Predi√ß√£o Perfeita')
plt.xlabel('Valores Reais')
plt.ylabel('Valores Preditos')
plt.title('Predi√ß√µes vs Valores Reais - Conjunto de Teste')
plt.legend()
plt.show()
```

#### Distribui√ß√£o dos Res√≠duos
```python
residuals = y_test - y_test_pred

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Histograma
axes[0].hist(residuals, bins=30, edgecolor='black')
axes[0].axvline(0, color='r', linestyle='--', linewidth=2)
axes[0].set_xlabel('Res√≠duo')
axes[0].set_ylabel('Frequ√™ncia')
axes[0].set_title('Distribui√ß√£o dos Res√≠duos')

# Res√≠duos vs Predi√ß√µes
axes[1].scatter(y_test_pred, residuals, alpha=0.5)
axes[1].axhline(0, color='r', linestyle='--', linewidth=2)
axes[1].set_xlabel('Valores Preditos')
axes[1].set_ylabel('Res√≠duos')
axes[1].set_title('Res√≠duos vs Predi√ß√µes')

plt.tight_layout()
plt.show()
```

#### An√°lise de Casos Extremos
```python
# Identificar piores predi√ß√µes
errors = np.abs(residuals)
worst_indices = errors.nlargest(10).index

print("10 PIORES PREDI√á√ïES:")
print(pd.DataFrame({
    'Real': y_test.iloc[worst_indices],
    'Predito': y_test_pred[worst_indices],
    'Erro Absoluto': errors.iloc[worst_indices]
}))
```

### 7. Salvamento do Modelo

**Salvar modelo treinado:**
```python
import joblib

# Criar pasta models (se n√£o existir)
import os
os.makedirs('models', exist_ok=True)

# Salvar modelo
joblib.dump(final_model, 'models/modelo_final.joblib')

print("‚úÖ Modelo salvo com sucesso!")

# Testar carregamento
loaded_model = joblib.load('models/modelo_final.joblib')
print("‚úÖ Modelo carregado com sucesso!")

# Verificar se funciona
test_prediction = loaded_model.predict(X_test[:5])
print("Predi√ß√µes de teste:", test_prediction)
```

---

## ‚úÖ Crit√©rios de Avalia√ß√£o

| Crit√©rio | Peso | O Que Avaliamos |
|----------|:----:|-----------------|
| **Otimiza√ß√£o de Hiperpar√¢metros** | 30% | Grid/Random Search executado, melhores params identificados |
| **Avalia√ß√£o Final** | 25% | M√©tricas no teste, compara√ß√£o antes/depois |
| **An√°lise de Erros** | 20% | Res√≠duos, casos extremos, interpreta√ß√£o |
| **Documenta√ß√£o** | 10% | Markdown claro, decis√µes justificadas |
| **Apresenta√ß√£o** | 15% | Clareza, participa√ß√£o, profundidade t√©cnica |

---

## üì¶ Como Entregar

### 1. Commit e Push
```bash
# Criar pasta models
mkdir -p models

git add notebooks/04_Otimizacao.ipynb
git add models/modelo_final.joblib
git commit -m "feat: Completa Etapa 4 - Otimiza√ß√£o e modelo final"
git push origin main
```

### 2. Apresenta√ß√£o
- Upload dos slides em `docs/apresentacao_etapa4.pdf`
- Apresentar na aula marcada pelo professor

---

## üí° Dicas Importantes

**DO:**
‚úÖ Documente TODOS os hiperpar√¢metros testados
‚úÖ Use valida√ß√£o cruzada durante o tuning
‚úÖ Analise POR QUE o modelo erra (n√£o s√≥ QUANTO)
‚úÖ Compare antes vs depois da otimiza√ß√£o
‚úÖ Teste o modelo salvo para garantir que funciona

**DON'T:**
‚ùå Usar o conjunto de teste durante o tuning (data leakage!)
‚ùå Fazer tuning sem valida√ß√£o cruzada
‚ùå Testar hiperpar√¢metros aleatoriamente sem crit√©rio
‚ùå Esquecer de salvar o modelo final
‚ùå Ignorar an√°lise de erros

---

## üéØ Checklist Antes de Entregar

- [ ] Grid Search ou Random Search executado
- [ ] Melhores hiperpar√¢metros identificados
- [ ] Modelo final treinado com TREINO + VALIDA√á√ÉO
- [ ] Avalia√ß√£o no conjunto de TESTE (uma √∫nica vez)
- [ ] Compara√ß√£o antes vs depois criada
- [ ] An√°lise de res√≠duos completa
- [ ] Casos extremos (piores erros) analisados
- [ ] Modelo salvo em `models/modelo_final.joblib`
- [ ] Notebook executa "Restart & Run All" sem erros
- [ ] Apresenta√ß√£o preparada (8-12 slides)

---

## üÜò Precisa de Ajuda?

**D√∫vidas comuns:**
- Grid Search vs Random Search? ‚Üí Grid = exaustivo mas lento; Random = mais r√°pido
- Quantos hiperpar√¢metros testar? ‚Üí Comece com 3-4 principais
- Overfitting ap√≥s tuning? ‚Üí Verifique valida√ß√£o cruzada, pode precisar regulariza√ß√£o

**Consulte:**
- Scikit-learn hyperparameter tuning: https://scikit-learn.org/stable/modules/grid_search.html
- XGBoost tuning guide: https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html
- Material da aula de otimiza√ß√£o

---

**√ìtima otimiza√ß√£o!** ‚ö°

*√öltima atualiza√ß√£o: Outubro 2027*
