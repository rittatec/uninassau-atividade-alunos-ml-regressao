# Etapa 2: Pr√©-processamento de Dados

**Prazo:** [Consultar calend√°rio]
**Peso:** 20% do projeto (2.0 pontos)
- 1.7 pontos: Notebook e arquivos
- 0.3 pontos: Apresenta√ß√£o

**Tempo estimado:** 6-8 horas

---

## üéØ Objetivo

Limpar e preparar os dados para a modelagem.

---

## üì¶ Entregas

1. **Notebook:** `notebooks/02_Preprocessamento.ipynb`
2. **Dataset limpo:** `data/students_clean.csv`
3. **Scaler salvo:** `models/scaler.pkl`
4. **üé§ Apresenta√ß√£o:** 5 minutos 

---

## üîß Tarefas (12 quest√µes)

### **Parte 1: Valores Faltantes** (2 quest√µes)

**Fazer:**
- Imputar num√©ricas com m√©dia ou mediana
- Imputar categ√≥ricas com moda
- Criar 2 gr√°fico (antes vs depois)

üëâ **Lembrete r√°pido**
- M√©dia funciona melhor quando a distribui√ß√£o √© equilibrada (sem outliers fortes).
- Mediana √© mais robusta a outliers; use-a quando a coluna for torta ou tiver valores extremos.

**Responder:**

**Q1.** Para cada vari√°vel num√©rica, voc√™ usou m√©dia ou mediana? Por qu√™?

**Q2.** Como evitar data leakage na Etapa 3?

---

### **Parte 2: Outliers** (2 quest√µes)

**Fazer:**
- Detectar outliers (m√©todo IQR)
- Decidir: remover ou manter
- Criar 1 boxplot (antes vs depois)

üìä **Entendendo o boxplot e o m√©todo IQR**
- **Q1 (1¬∫ quartil):** 25% dos valores est√£o abaixo desse ponto.
- **Q3 (3¬∫ quartil):** 75% dos valores est√£o abaixo desse ponto.
- **IQR (Q3 - Q1):** faixa onde est√° a metade central dos dados.
- **Outliers (regra 1.5√óIQR):** valores abaixo de Q1 - 1.5√óIQR ou acima de Q3 + 1.5√óIQR.
- No boxplot: a caixa vai de Q1 a Q3, a linha no meio √© a mediana; os ‚Äúpontinhos‚Äù fora dos bigodes s√£o outliers.

**Responder:**

**Q3.** Quantos outliers voc√™ detectou em cada coluna?

**Q4.** Voc√™ removeu algum outlier? Por qu√™?

---

### **Parte 3: Limpeza** (1 quest√£o)

**Fazer:**
- Remover duplicatas

**Responder:**

**Q5.** Quantas duplicatas voc√™ removeu?

---

### **Parte 4: Distribui√ß√µes e Assimetria (Skewness)** (2 quest√µes)

**Fazer:**
- Calcular skewness das colunas num√©ricas
- Identificar distribui√ß√µes assim√©tricas (skew > 0.5 ou < -0.5)
- Aplicar transforma√ß√£o (log ou sqrt) se necess√°rio

üí° **Por que olhar para skewness?** Distribui√ß√µes muito assim√©tricas podem prejudicar modelos lineares. Transforma√ß√µes ajudam a aproximar a curva de uma forma mais ‚Äúnormal‚Äù e reduzem o impacto de outliers.

**Responder:**

**Q6.** Quais colunas t√™m distribui√ß√£o assim√©trica (skew > 0.5)?

**Q7.** Voc√™ aplicou transforma√ß√£o em alguma coluna? Qual?

**üìö Para entender:**
- **Skewness > 0:** Cauda √† direita (assimetria positiva)
- **Skewness < 0:** Cauda √† esquerda (assimetria negativa)
- **|Skewness| > 0.5:** Considere transformar (log, sqrt, Box-Cox)

---

### **Parte 5: Encoding** (2 quest√µes)

**Fazer:**
- One-Hot para nominais (usar `drop_first=True`)
- LabelEncoder para vari√°veis ordinais

üî† **Qual encoder usar?**
- **One-Hot Encoder:** use para vari√°veis **nominais** (categorias sem ordem), ex.: `gender`, `city`. Cria uma coluna 0/1 para cada categoria e evita comparar ‚Äúmaior/menor‚Äù.
- **LabelEncoder:** use apenas para vari√°veis **ordinais** (categorias com ordem l√≥gica), ex.: `education = {fundamental < m√©dio < superior}`. Converte as categorias em n√∫meros inteiros preservando a ordem.
- `drop_first=True` remove uma das colunas One-Hot para evitar multicolinearidade (informa√ß√£o redundante) e funciona como categoria de refer√™ncia.

**Responder:**

**Q8.** Quantas colunas One-Hot foram criadas?

**Q9.** Por que usar `drop_first=True`?

---

### **Parte 6: Feature Engineering** (1 quest√£o)

**Fazer:**
- Criar **2 novas features**
- Calcular correla√ß√£o com target(alvo)

**Responder:**

**Q10.** Liste as 2 features criadas e explique cada uma.

---

### **Parte 7: Normaliza√ß√£o** (2 quest√µes)

**Fazer:**
- Aplicar StandardScaler
- **Salvar scaler:** `joblib.dump(scaler, 'models/scaler.pkl')`

üìè **O que √© um scaler?**
- O `StandardScaler` padroniza colunas num√©ricas para terem **m√©dia 0** e **desvio-padr√£o 1**.
- Isso evita que vari√°veis em escalas diferentes (ex.: renda vs. horas de estudo) dominem o modelo.
- Sempre `fit` no treino e `transform` no treino **e** no teste para evitar data leakage.
- Salvar o scaler permite aplicar a mesma transforma√ß√£o em dados futuros (deploy).

**Responder:**

**Q11.** Quantas features voc√™ escalou?

**Q12.** Por que salvar o scaler?

---

## üìä Visualiza√ß√µes (m√≠nimo 4)

1. **Missing:** Barras (antes vs depois)
2. **Outliers:** Boxplot (antes vs depois)
3. **Distribui√ß√µes:** Histogramas mostrando skewness (antes e depois da transforma√ß√£o)
4. **Normaliza√ß√£o:** Histogramas (antes vs depois do StandardScaler)

üìå **Sugest√£o para interpretar gr√°ficos:** Em cada slide ou resposta, descreva brevemente o que o gr√°fico mostra, qual decis√£o voc√™ tomou (ex.: remover outliers, usar mediana) e por qu√™ isso melhora o modelo.


## üí° Dicas de C√≥digo

```python
# 1. Imputa√ß√£o
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='median')
df[cols] = imputer.fit_transform(df[cols])

# Fluxo completo (treino x teste) para evitar data leakage
from sklearn.model_selection import train_test_split

# Separar features (X) e target (y)
X = df.drop('final_grade', axis=1)
y = df['final_grade']

# Dividir em treino e teste (80/20)
X_train, X_test, y_train, y_test = train_test_split(
	X, y, test_size=0.2, random_state=42
)

# Selecionar apenas as colunas num√©ricas para imputa√ß√£o
numeric_cols_train = X_train.select_dtypes(include=np.number).columns

imputer = SimpleImputer(strategy='mean')
imputer.fit(X_train[numeric_cols_train])            # aprende com o TREINO

X_train_imputed = imputer.transform(X_train[numeric_cols_train])
X_test_imputed = imputer.transform(X_test[numeric_cols_train])   # reutiliza m√©dias do treino

# Converter de volta para DataFrame (opcional, mas ajuda na inspe√ß√£o)
X_train_imputed = pd.DataFrame(X_train_imputed,
							   columns=numeric_cols_train,
							   index=X_train.index)
X_test_imputed = pd.DataFrame(X_test_imputed,
							  columns=numeric_cols_train,
							  index=X_test.index)

print("Imputa√ß√£o conclu√≠da sem data leakage!")
print("Treino:", X_train_imputed.shape, "Teste:", X_test_imputed.shape)

# 2. Outliers (IQR)
Q1 = df['col'].quantile(0.25)
Q3 = df['col'].quantile(0.75)
IQR = Q3 - Q1
outliers = df[(df['col'] < Q1-1.5*IQR) | (df['col'] > Q3+1.5*IQR)]

# 3. Duplicatas
df = df.drop_duplicates()

# 4. Skewness (Assimetria)
from scipy.stats import skew
skewness = df.select_dtypes(include=[np.number]).apply(lambda x: skew(x))
print(skewness)

# Transforma√ß√µes para corrigir assimetria
# a) Assimetria positiva (cauda √† direita): usar log
import numpy as np
df['col_transformed'] = np.log1p(df['col'])  # log1p = log(1+x), evita log(0)

# b) Assimetria positiva moderada: usar sqrt
df['col_transformed'] = np.sqrt(df['col'])

# c) Box-Cox (mais avan√ßado)
from scipy.stats import boxcox
df['col_transformed'], lambda_param = boxcox(df['col'] + 1)  # +1 se houver zeros

# 5. One-Hot
df = pd.get_dummies(df, columns=['gender'], drop_first=True)

# 6. Normaliza√ß√£o (StandardScaler)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[cols] = scaler.fit_transform(df[cols])

# 7. Salvar scaler
import joblib
joblib.dump(scaler, 'models/scaler.pkl')

# 8. Visualizar distribui√ß√µes antes/depois
import matplotlib.pyplot as plt
fig, axes = plt.subplots(1, 2, figsize=(12, 4))
axes[0].hist(df['col_original'], bins=30)
axes[0].set_title(f'Antes (skew={skew(df["col_original"]):.2f})')
axes[1].hist(df['col_transformed'], bins=30)
axes[1].set_title(f'Depois (skew={skew(df["col_transformed"]):.2f})')
plt.show()
```

---

## üìö Links √öteis

- [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)
- [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)
- [get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)
- [scipy.stats.skew](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skew.html)
- [Transforma√ß√µes Box-Cox](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html)

---

## ÔøΩ Gloss√°rio R√°pido

- **Data Leakage:** usar informa√ß√µes do conjunto de teste durante o treino (direta ou indiretamente). Sempre calcule m√©dias, mediana, scaler e encoders **s√≥** no treino.
- **Q1 / Q3:** 25¬∫ e 75¬∫ percentis de uma coluna. O intervalo [Q1, Q3] cont√©m a ‚Äúfaixa central‚Äù dos dados.
- **IQR:** `Q3 - Q1`. Ajuda a detectar outliers com a regra `1.5 √ó IQR`.
- **Boxplot:** gr√°fico que mostra mediana, Q1, Q3 e outliers. √ötil para justificar remo√ß√£o/manuten√ß√£o de valores extremos.
- **One-Hot Encoder:** transforma categorias sem ordem em colunas bin√°rias (0/1). Ideal para vari√°veis nominais.
- **LabelEncoder:** converte categorias com ordem em n√∫meros (0, 1, 2, ‚Ä¶). Ideal para vari√°veis ordinais.
- **StandardScaler:** padroniza colunas para m√©dia 0 e desvio 1. Mant√©m todas as vari√°veis na mesma escala.
- **Skewness:** medida de assimetria. Valores altos indicam cauda longa; considere transformar antes de modelar.

---

## ÔøΩüö´ Evite

‚ùå Calcular m√©dia/mediana com TODO o dataset
‚ùå N√£o salvar o scaler
‚ùå Esquecer `drop_first=True`
‚ùå Ignorar distribui√ß√µes assim√©tricas
‚ùå Aplicar log em colunas com zeros (use log1p)

---

## üé§ Apresenta√ß√£o (5 minutos)

### Estrutura dos Slides

**Slide 1: Problemas Corrigidos**
- Valores faltantes: X removidos/imputados
- Outliers: Y detectados, Z removidos
- Duplicatas: W removidas

**Slide 2: Transforma√ß√µes de Distribui√ß√£o (Skewness)**
- Colunas com alta assimetria identificadas
- Transforma√ß√µes aplicadas (log, sqrt, etc.)
- Mostrar 1 gr√°fico antes/depois

**Slide 3: Features Criadas**
- Feature 1: [nome] - correla√ß√£o = X.XX
- Feature 2: [nome] - correla√ß√£o = X.XX

**Slide 4: Resultado Final**
- Dataset original: X linhas, Y colunas
- Dataset limpo: X linhas, Z colunas
- Pronto para modelagem ‚úÖ

### Dicas para Apresenta√ß√£o

‚úÖ **M√°ximo 5 minutos** - Ensaie com cron√¥metro
‚úÖ **Todos participam** - ~1 min por pessoa
‚úÖ **Seja objetivo** - Mostre n√∫meros e gr√°ficos
‚úÖ **Salve os slides** - `docs/apresentacao_etapa2.pdf`

---

## üìÇ Template

Use o template em `notebooks/02_Preprocessamento_TEMPLATE.py`

```bash
cd notebooks
cp 02_Preprocessamento_TEMPLATE.py 02_Preprocessamento.py
# Abrir e preencher TODOs
```

---

## üì• Como Entregar

```bash
# 1. C√≥digo
git add notebooks/02_Preprocessamento.py
git add data/students_clean.csv
git add models/scaler.pkl

# 2. Apresenta√ß√£o
git add docs/apresentacao_etapa2.pdf

# 3. Commit e push
git commit -m "feat: Completa Etapa 2 - Pr√©-processamento"
git push origin main
```

---

**D√∫vidas?** Atendimento ou Issues no GitHub
**Boa sorte!** üöÄ
